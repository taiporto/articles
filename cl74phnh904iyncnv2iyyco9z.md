---
title: "Entendendo Big O Notation - O que √© e como us√°-la para avaliar a complexidade de execu√ß√£o de algoritmos"
seoTitle: "Como analisar a complexidade de algoritmos com Big O Notation"
seoDescription: "Entenda com exemplos o que √© Big O e como ela pode ser usada para analisar a performance de qualquer algoritmo."
datePublished: Mon Aug 22 2022 12:00:00 GMT+0000 (Coordinated Universal Time)
cuid: cl74phnh904iyncnv2iyyco9z
slug: entendendo-big-o-notation
cover: https://cdn.hashnode.com/res/hashnode/image/unsplash/pFJtmoDMSAo/upload/v1656363614932/93UhaYTL_.jpeg
tags: teoria

---

Quando comecei a aprender programa√ß√£o existiam muitos assuntos dos quais eu simplesmente fugia. O que fez mais sentido na minha cabe√ßa foi primeiro aprender como *fazer* as coisas e depois como otimiz√°-las.

Por isso, deixei de lado alguns assuntos como Big O Notation e Design Patterns. At√© que conseguisse o b√°sico, para mim n√£o fazia sentido procurar lidar com a complexidade desses temas.

Agora, voltando a esss temas, Big O Notation foi um dos assuntos que mais me trouxe receio. Primeiro, porque envolve matem√°tica (pequenos traumas üòÖ). Segundo, porque as primeiras introdu√ß√µes que tive ao tema foram, embora excelentes em detalhamento, muito complexas. Com isso, quase me desanimei de aprender. Mas recentemente comecei um curso na Udemy chamado [JavaScript Algorithms and Data Structures Masterclass](https://www.udemy.com/course/js-algorithms-and-data-structures-masterclass/) que tem uma introdu√ß√£o excelente ao assunto.

As explica√ß√µes neste post ser√£o todas baseadas nesse curso da Udemy, que recomendo bastante.

## Come√ßando pelo come√ßo - O que √© Big O Notation?

Imagine que duas pessoas s√£o desafiadas a resolver um mesmo problema:

> Crie um programa que some todos os n√∫meros de 1 a N, incluindo N.

Uma das melhores partes da programa√ß√£o √© que existem milhares de formas de resolver um mesmo problema. Essas duas pessoas podem ir por caminhos totalmente diferentes e chegar em solu√ß√µes v√°lidas.

Uma das pessoas pensou nessa solu√ß√£o:

```javascript
function somaAteN(numero){
	let soma = 0;
	for(let i = 1; i <= numero; i++){
		soma += i;
	}
	return soma;
}
```

E a outra pessoa pensou nessa solu√ß√£o aqui:

```javascript
function somaAteN(numero){
	return numero * (numero + 1) / 2;
}
```

No final, o que costuma importar √© se a solu√ß√£o funciona. A princ√≠pio n√£o existe como determinar se um c√≥digo √© "melhor" ou "pior" do que o outro se n√£o determinamos antes qual o par√¢metro de qualidade. O que determina um c√≥digo "bom"?

Podemos pensar em alguns par√¢metros. Um c√≥digo pode ser bom se:

1. √â leg√≠vel;
    
2. **√â r√°pido;**
    
3. **Consome menos recursos;**
    

Muitas vezes o que vai ser priorizado s√£o os dois √∫ltimos itens, especialmente o n√∫mero 2. Mas medir a rapidez de um c√≥digo n√£o √© uma tarefa t√£o simples quanto pode parecer.

## Os problemas de medir rapidez

Resumindo em uma linha o maior problema ao tentar medir rapidez de execu√ß√£o: **m√°quinas n√£o s√£o todas iguais, e n√£o rodam os mesmos processos sempre da mesma forma**.

N√≥s poder√≠amos criar um timer, ou marcar o tempo logo antes e logo ap√≥s a execu√ß√£o de um algoritmo para comparar a diferen√ßa, mas esse tempo pode variar entre m√°quinas e at√© mesmo entre as vezes em que o algoritmo √© executado em uma mesma m√°quina.

Al√©m disso:

1. Usar um timer funciona apenas para algoritmos com entradas pequenas e que podem ser executados como teste.
    
2. Marcar o tempo dessa forma n√£o √© produtivo para analisar a performance de diferentes algoritmos **antes** de implement√°-los, j√° que torna obrigat√≥rio execut√°-los.
    
3. Em um contexto de recursos e tempo limitados pode n√£o ser muito vantajoso executar um algoritmo e gastar recursos s√≥ para conferir seu tempo de execu√ß√£o.
    
4. Com resultados vari√°veis n√£o existe como estabelecer uma escala precisa ou qualquer padr√£o al√©m de "esse algoritmo toma muito tempo" e "esse toma pouco tempo".
    

Por esses aspectos, medir a rapidez em segundos/minutos/horas torna-se um problema. Mas ainda assim, √© preciso alguma forma de comparar algoritmos, certo?

O que a Big O Notation se prop√µe a fazer √© apenas estabelecer uma **linguagem padronizada** para comparar n√£o a rapidez, mas a **complexidade de execu√ß√£o** entre c√≥digos diferentes que resolvem os mesmos problemas.

## Como calcular Big O Notation?

Se calcular a rapidez de um c√≥digo com m√©todos como configurar um cron√¥metro leva a resultados pouco constantes, de que outra forma podemos fazer esse c√°lculo?

A resposta mais simples √©: contando opera√ß√µes.

Um computador pode variar de outro no tempo que leva para executar um c√≥digo. Mas, no final das contas, todos eles v√£o executar as mesmas opera√ß√µes determinadas pelo algoritmo. Algumas dessas opera√ß√µes ser√£o, por defini√ß√£o, mais complexas, ou seja, exigir√£o mais tempo do que outras.

Trazendo de volta os exemplos anteriores, podemos testar esse racioc√≠nio de contar opera√ß√µes.

```javascript
// Solu√ß√£o 1
function somaAteN(numero){
	let soma = 0;
	for(let i = 1; i <= numero; i++){
		soma += i;
	}
	return soma;
}
```

Se listarmos as opera√ß√µes realizadas pela fun√ß√£o `somaAteN` na Solu√ß√£o 1, temos:

1. `let soma = 0;` -&gt; Cria√ß√£o de vari√°vel e designa√ß√£o de valor.
    
2. `let i = 1;` -&gt; Mais uma cria√ß√£o de vari√°vel e designa√ß√£o de valor. Primeira opera√ß√£o do loop de repeti√ß√£o.
    
3. `i <= numero;` -&gt; Compara√ß√£o e segunda opera√ß√£o do loop.
    
4. `i++;` -&gt; Designa√ß√£o e adi√ß√£o. Terceira opera√ß√£o do loop.
    
5. `soma += i;` - Novamente, designa√ß√£o e adi√ß√£o. Quarta opera√ß√£o do loop.
    
6. `return soma;` - Nossa opera√ß√£o de sa√≠da.
    

As opera√ß√µes 4 e 5 s√£o duplas ‚Äì usam uma sintaxe reduzida para abreviar o que seriam duas opera√ß√µes. Portanto, podem contar como duas opera√ß√µes cada. Assim, temos, no total, mais ou menos 8 opera√ß√µes.

Mas poder√≠amos dizer com certeza que, toda vez que a Solu√ß√£o 1 rodar, o n√∫mero **total** de opera√ß√µes vai ser 8?

![Um minion, personagem amarelo e baixinho do desenho animado Meu Malvado Favorito, falando ao telefone e dizendo "√â... N√£o.‚Äù](https://media.giphy.com/media/gnE4FFhtFoLKM/giphy.gif align="center")

Pois √©... N√£o.

Porque estamos esquecendo de uma coisa muito importante: O loop de repeti√ß√£o!

Com ele, as opera√ß√µes que s√£o parte do loop e reavaliadas em cada itera√ß√£o (ou seja, todas no loop sem contar a declara√ß√£o inicial `let i = 1`) s√£o contadas n vezes de acordo com o valor da entrada `n`.

E √© aqui que a coisa come√ßa a complicar para a Solu√ß√£o 1. Vamos supor que queremos somar todos os n√∫meros de 1 at√© 10, incluindo o 10. Nesse caso, nossa **entrada**, nosso `n`, √© 10, certo?

Ent√£o vamos ter como constantes as opera√ß√µes 1 e 2. At√© aqui temos 2 opera√ß√µes. Beleza.

Depois, declaramos que o loop de repeti√ß√£o roda enquanto `i` for menor ou igual a `n`, ou seja, 10. Portanto, as outras 6 opera√ß√µes v√£o rodar **10 vezes**. Com isso, ter√≠amos:

> `2 + (6 * 10)`

Em que `2` s√£o as nossas duas opera√ß√µes constantes, `6` s√£o as opera√ß√µes restantes que dependem do valor de `n` e `10` √© o valor de `n`.

Ou

> O(2 + 6n)

Em que o `O()` √© a sintaxe usada para mostrar que estamos falando de Big O. Nesse caso podemos "falar" a express√£o acima da seguinte forma: "O Big O da solu√ß√£o 1 √© igual a 2 mais 6n"

Mas n√£o terminamos aqui. Antes de continuarmos, √© importante destacar um fator dessa linguagem que estamos usando para falar de complexidade:

<div data-node-type="callout">
<div data-node-type="callout-emoji">üí°</div>
<div data-node-type="callout-text">Big O funciona em uma escala afastada, como se olh√°ssemos todo o nosso algoritmo bem de cima. Nessa vis√£o geral, certas opera√ß√µes e valores n√£o importam tanto, visto que adicionariam um tempo de execu√ß√£o √≠nfimo ou pouco mensur√°vel. Ent√£o, ao contabilizar as opera√ß√µes sempre buscamos <strong>simplificar ao m√°ximo</strong>.</div>
</div>

Por isso, quando temos `O(2 + 6n)` esse valor pode ser simplificado para somente `O(n)`. Isso acontece porque se f√¥ssemos comparar a diferen√ßa de performance da Solu√ß√£o 1 entre uma entrada `n` de valor 10 e uma de valor 10.000, a maior diferen√ßa no tempo de execu√ß√£o se daria pelo tamanho dessa entrada `n`, e n√£o pelas constantes 2 e 6.

Assim, podemos dizer que o Big O da Solu√ß√£o 1 √© `O(n)`, ou seja, seu tempo de execu√ß√£o tende a crescer linearmente conforme `n` cresce.

### Beleza... mas e a solu√ß√£o 2?

A solu√ß√£o 2! Vamos l√°:

```javascript
// Solu√ß√£o 2
function somaAteN(numero){
	return numero * (numero + 1) / 2;
}
```

J√° podemos ver de primeira que o n√∫mero de opera√ß√µes √© menor que o da solu√ß√£o anterior, mesmo se desconsiderarmos a quantidade extra de opera√ß√µes da Solu√ß√£o 1 por causa do loop. Temos:

1. numero \* ... - Multiplica√ß√£o;
    
2. (numero + 1) - Opera√ß√£o de adi√ß√£o;
    
3. ... / 2 - Opera√ß√£o de divis√£o;
    

Como a Solu√ß√£o 2 n√£o implementa nenhum loop, para qualquer valor de `n` o n√∫mero de opera√ß√µes realizado vai ser o mesmo: 3.

Assim, temos que o Big O da Solu√ß√£o 2 poderia ser `O(3)`. Mas, novamente, Big O olha tudo bem de cima, em uma escala muito afastada. Al√©m disso, a Big O Notation n√£o se importa muito com constantes. O que importa √© entender **como um algoritmo se comporta em rela√ß√£o √† sua entrada, o** `n`.

Por isso, o nosso `O(3)` pode ser simplificado para `O(1)`, que √©, finalmente, o Big O da nossa Solu√ß√£o 2.

Esse `O(1)` n√£o significa nada mais do que o que j√° foi dito antes:

> Como a Solu√ß√£o 2 n√£o implementa nenhum loop, para qualquer valor de `n` o n√∫mero de opera√ß√µes realizado vai ser sempre o mesmo.

Por isso, dizemos que essa solu√ß√£o tem uma complexidade de execu√ß√£o constante.

> `O(1)` = Complexidade constante independentemente do valor de `n`

Essa √© a forma padronizada de escrever e falar sobre o assunto. A ideia do Big O √© fazer com que em uma conversa entre programadores todos cheguem ao mesmo racioc√≠nio ao escutarem ou lerem `O(1)`, `O(n)`, e assim por diante.

## Como interpretar Big O Notation?

Ent√£o quando voc√™ encontrar coisas sobre Big O, vai ver nota√ß√µes como `O(n)`, `O(1)`, `O(n¬≤)`, `O(n^c)`, etc. Mas... o que elas significam?

Olhando para os exemplos anteriores j√° sabemos que `O(1)` significa um algoritmo que mant√©m um tempo de execu√ß√£o constante independentemente do tamanho da entrada. Tamb√©m sabemos que `O(n)` significa um algoritmo cujo tempo de execu√ß√£o cresce linearmente e proporcionalmente ao tamanho de sua entrada.

A Big O Notation busca calcular a complexidade de tempo que um algoritmo leva para ser executado e o quanto essa complexidade muda baseando-se na entrada oferecida a ele. Mas √© importante saber que **a Big O vai considerar sempre o Pior Cen√°rio Poss√≠vel**. N√£o necessariamente um algoritmo vai sempre atingir esse teto de complexidade, seja ele O(n), O(n^2) ou qualquer outro. O importante √© estabelecer o teto.

> üí° Existem outros m√©todos de c√°lculo de complexidade que determinam limites diferentes do pior cen√°rio poss√≠vel:

* [Big Theta (Œò) Notation](https://www.khanacademy.org/computing/computer-science/algorithms/asymptotic-notation/a/big-big-theta-notation) - Considera **o pior cen√°rio poss√≠vel e o melhor cen√°rio poss√≠vel**, estabelecendo um tempo de execu√ß√£o que √© a m√©dia entre esses dois limites.
    
* [Big Omega (Œ©) Notation](https://www.khanacademy.org/computing/computer-science/algorithms/asymptotic-notation/a/big-big-omega-notation) - Considera **o melhor cen√°rio poss√≠vel**, estabelecendo um piso de complexidade. O tempo de execu√ß√£o dos algoritmos pode ser maior, mas nunca menor do que o Big Omega.
    

Existem alguns resultados b√°sicos de Big O que v√£o aparecer frequentemente:

* `O(1)` - Significa que o algoritmo tem uma complexidade de execu√ß√£o constante. Seu tempo de execu√ß√£o vai seguir relativamente igual n√£o importa o quanto a sua entrada cres√ßa.
    
* `O(log n)` - A complexidade cresce um pouco conforme `n` cresce, mas de forma menos acelerada do que `O(n)`. **√â considerado o "ponto ideal" da complexidade de algoritmos** e √© a complexidade do algortimo chamado de ***Binary Search*** (Busca bin√°ria) ou "***divide-and-conquer***" (Divida e conquiste). [Este artigo](https://hackernoon.com/what-does-the-time-complexity-o-log-n-actually-mean-45f94bb5bfbf) no Hackernoon tem uma explica√ß√£o bastante visual de como chegar em `O(log n)` analisando um algoritmo de busca bin√°ria.
    
* `O(n)` - A complexidade cresce proporcionalmente ao crescimento da entrada `n`, proporcionando um aumento linear ao tempo de execu√ß√£o.
    
* `O(n¬≤)` - Chamamos essa complexidade de complexidade quadr√°tica. Quando um algoritmo roda em `O(n¬≤)`, seu tempo de execu√ß√£o cresce em uma curva ascendente conforme `n` aumenta. Um exemplo muito visto √© aquele em que √© necess√°rio aninhar um loop de repeti√ß√£o dentro do outro:
    

```javascript
function manipulaArray2D(arr){
  for(let i = 0; i <= arr.length; i++) {
    for(let j = 0; j <= arr.length; j++){
      //... fa√ßa algo
    }
  }
}
```

* `O(n^c)` - E por que parar em uma complexidade quadr√°tica? A complexidade O(n^c) √© chamada de polinomial. Ela aumenta com base n√£o apenas no valor da entrada `n`, mas tamb√©m com base no n√∫mero de repeti√ß√µes aninhadas baseadas em `n`. O n√∫mero de repeti√ß√µes √© o expoente `c`.
    

Al√©m desses, existem outros especificados na imagem abaixo, como `O(2^n)`, `O(n!)` e `O(n log n)`.

![Gr√°fico demonstrando a complexidade dos Big-Os listados. O(1) e O(log n) est√£o em uma √°rea boa, O(n) e O(n log n) est√£o em uma m√©dia e O(n¬≤), O(2^n) e O(n!) est√£o em uma √°rea ruim](https://cdn.hashnode.com/res/hashnode/image/upload/v1656370466510/TMc-cS7A9.png align="left")

## O poder das cheat sheets

√â muita coisa pra lembrar, n√©? A parte boa √© que desenvolvedores amam *cheat sheets*, aquela colinha que te lembra rapidamente do significado ou da aplica√ß√£o de um termo espec√≠fico. A imagem aqui em cima que ilustra o tempo de execu√ß√£o de cada um dos Big Os foi retirada da [Big-O Cheat Sheet](https://www.bigocheatsheet.com/), que tamb√©m possui uma tabela de algoritmos comuns de manipula√ß√£o de arrays e suas respectivas complexidades de execu√ß√£o.

Big O √© um assunto super extenso, e exige muito mais pesquisa e aprofundamento do que esse artigo √© capaz de proporcionar. Mas espero que ele sirva como uma boa introdu√ß√£o ao assunto e, como antes, sigo recomendando o curso [JavaScript Algorithms and Data Structures Masterclass](https://www.udemy.com/course/js-algorithms-and-data-structures-masterclass/), disponibilizado na Udemy. At√© a pr√≥xima!